---
title: 9.4 Inference About Slope
createTime: 2024/09/25 20:49:20
permalink: /MATH2099/uxx7wb1t/
---

<script setup>
import HSelect from "@HSelect"
</script>


## Question 1

<div class="how_qb">

**Concept**

<iframe width="672" height="378" src="https://www.youtube.com/embed/ke2cSah2vXU" title="L9 10 Standard Error of the Slope" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

Video Recap

- Under our regression assumptions, the least squares estimator of the slope is normally distributed with mean $\beta_1$ and standard error $\frac{\sigma}{\sqrt{s_{xx}}}$. (This remains approximately true, by the Central Limit Theorem, even if the normality assumption is not satisfied.)
- We estimate the error variance $\sigma^2$ using $s^2 = \frac{1}{n-2} \sum_{i=1}^n \hat{e}_i^2$.
- The estimator of the error variance has $n-2$ degrees of freedom (subtracting two because there are two parameters in our model for the conditional mean).
- The estimated standard error of the slope appears in simple linear regression output in the $\texttt{SE}$ column, in the second row in the output (which is labelled $\texttt{x1}$ on Matlab)

</div>

## Question 2

<div class="how_qb">

**Concept**

<iframe width="672" height="378" src="https://www.youtube.com/embed/0zMr8D1EC5g" title="L9 11 Testing Hypotheses about the Slope" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

Video Recap

- If $Y$ is independent of $X$, the true slope is zero: $\beta_1=0$. So this is our null hypothesis if we are testing if there is evidence that two variables are related.
- If regression assumptions are satisfied,
$$\frac{\hat{\beta}_1-\beta_1}{S/\sqrt{s_{xx}}}  \sim t_{n-2} $$
- Under the null hypothesis $H_0:\ \beta_1=0$, $\frac{\hat{\beta}}{S/\sqrt{s_{xx}}}  \sim t_{n-2}$
- This test statistic appears in regression output in the column labelled $\texttt{tStat}$, again in the second row, and the $P$-value from a two-sided test appears in the $\texttt{pValue}$ column of the second row.

</div>

## Question 3

<div class="how_qb">

**Example**

Consider again the oxygen distillation example.

Is there evidence of a relationship between oxygen purity and hydrocarbon concentration? Perform the appropriate hypothesis test.

We test:

$H_0:$ <HSelect type="Mobius" :values="[
    {label: 'π'},
    {label: 'β₀'},
    {label: 'β₁', selected: true},
    {label: 'μ'}]" /> <HSelect type="Mobius" :values="[
    {label: '≥'},
    {label: '≠'},
    {label: '=', selected: true},
    {label: '≤'}]" /> `0` (*Enter the exact value)*

against:

$H_a:$ <HSelect type="Mobius" :values="[
    {label: 'π'},
    {label: 'β₀'},
    {label: 'β₁', selected: true},
    {label: 'μ'}]" /> <HSelect type="Mobius" :values="[
    {label: '≥'},
    {label: '≠', selected: true},
    {label: '='},
    {label: '≤'}]" /> `0` (*Enter the exact value)*

Our test statistic takes the value `11.19` (*Enter your answer correct to 2 decimal places)*

which would come from a $t$ distribution with   degrees ot freedom, if $H_0$ were true. `18` (*Enter the exact value)*

Our $P$-value is inside which range of values: <HSelect type="Mobius" :values="[
    {label: '[0, 0.001]', selected: true},
    {label: '[0.001, 0.01]'},
    {label: '[0.01, 0.1]'},
    {label: '[0.1, 1]'}]" />

Which of these is an appropriate conclusion?

- [x] We have very strong evidence against $H_0$, that is, we have very strong evidence that oxygen purity is related to hydrocarbon concentration.

- [ ] We have very strong evidence that $H_0$ is true, that is, we have very strong evidence that oxygen purity is not related to hydrocarbon concentration.

- [ ] We have very strong evidence against $H_a$, that is, we have very strong evidence that oxygen purity is not related to hydrocarbon concentration.

- [ ] We have very strong evidence that $H_a$ is true, that is, we have very strong evidence that oxygen purity is not related to hydrocarbon concentration.

<iframe width="672" height="378" src="https://www.youtube.com/embed/Gs1s011qKT4" title="L9 13 Hypothesis Test for Slope Exercise" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

</div>

## Question 4

<div class="how_qb">

**Concept**

<iframe width="672" height="378" src="https://www.youtube.com/embed/aVGBj-y-sXc" title="L9 12 Confidence Interval for the Slope" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

 Video Recap

- A $100(1-\alpha)$% confidence interval for the true slope $\beta_1$ can be constructed using
$$\left[\hat{b}_1-t_{n-2;1-\alpha/2}\frac{s}{\sqrt{s_{xx}}},\hat{b}_1+t_{n-2;1-\alpha/2}\frac{s}{\sqrt{s_{xx}}} \right]$$
- This can be computed relatively easily from regression output, which gives us the slope estimate $\hat{b}_1$ and its standard error $\frac{s}{\sqrt{s_{xx}}}$, all we need is to compute the appropriate critical value from the $t_{n-2}$ distribution.
- The confidence interval can be constructed even more directly on Matlab using the $\texttt{coefCI}$ function.

</div>

## Question 5

<div class="how_qb">

**Example**

Construct a 99% confidence interval for the expected increase in oxygen purity when hydrocarbon concentration increases by 1 unit.

( `11.13` , `18.84` )  (*Enter your answers correct to 2 decimal places)*

<iframe width="672" height="378" src="https://www.youtube.com/embed/y4BGjaonakc" title="L9 14 Confidence Interval for Slope Exercise" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

</div>