---
title: 4.5 Properties of estimators
createTime: 2024/09/05 21:19:21
permalink: /MATH2099/5pnh90bj/
---

## Question 1

<div class="how_qb">

**Concept**

<iframe width="672" height="378" src="https://www.youtube.com/embed/QllzO99vplA" title="L4 14 Unbiased Estimators" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

Video Recap

- The first desirable property of an estimator is that it is **unbiased**.
- An estimator $\hat{\Theta}$ of $\theta$ is said to be unbiased if and only if its mean is equal to $\theta$, i.e. $\mathbb{E}\left(\hat{\Theta}\right)=\theta$.
- If an estimator is not unbiased, then the difference $\mathbb{E}(\hat{\Theta})-\theta$ is called the **bias** of the estimator.


</div>

## Question 2

<div class="how_qb">

**Example**

We take a random sample $X_1,X_2,\ldots X_n$ from a distribution with mean $\mu$. Consider the following estimators:

- $\hat{\Theta}_1=X_1$, the first observed value
- $\hat{\Theta}_2=\dfrac{(X_1+X_n)}{2}$
- $\hat{\Theta}_3=\dfrac{(2X_1+X_n)}{2}$


Compute the following expectations:

*(Enter your answers in terms of $\mu$)*

$\mathbb{E} \left(\hat{\Theta}_1\right) =$ `mu` $(\mu)$


$\mathbb{E} \left(\hat{\Theta}_2\right) =$ `mu` $(\mu)$


$\mathbb{E} \left(\hat{\Theta}_3\right) =$ `3/2*mu` $(\frac{3}{2} \mu)$


Hence, which of $\hat{\Theta}_1$, $\hat{\Theta}_2$ and $\hat{\Theta}_3$ are unbiased for $\mu$?

- [x] $\hat{\Theta}_1$

- [x] $\hat{\Theta}_2$

- [ ] $\hat{\Theta}_3$

<iframe width="672" height="378" src="https://www.youtube.com/embed/B-stiEePk_g" title="L4 15 Unbiased Estimator Example" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

</div>

## Question 3

<div class="how_qb">

**Concept**

<iframe width="672" height="378" src="https://www.youtube.com/embed/ITpyk2zpJuc" title="L4 16 Efficient Estimators" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

Video Recap

- If an unbiased estimator has smaller variance, its estimates are usually closer to the true value of the parameter and it is more **efficient**.

</div>


## Question 4

<div class="how_qb">

**Concept**

<iframe width="672" height="378" src="https://www.youtube.com/embed/707RWnZ6oiI" title="L4 17 Consistent Estimators" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

Video Recap

- An estimator is **consistent** if the probability that the estimator is 'close' to $\theta$ increases to one as the sample size increases.
- An easy way to check that an unbiased estimator is consistent is to show that its variance decreases to 0 as $n$ increases to $\infty$.

</div>





